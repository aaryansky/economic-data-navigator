{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136ee802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 press release files to process.\n",
      "\n",
      "Processing file: Press Release for auction of G-Sec- 11.08.2025.pdf...\n",
      "--> Warning: Could not locate table boundaries.\n",
      "\n",
      "Processing file: Press Release for auction of G-Sec- 21.07.2025.pdf...\n",
      "--> Warning: Could not locate table boundaries.\n",
      "\n",
      "Processing file: Press Release for auction of G-Sec- 28.07.2025.pdf...\n",
      "--> Warning: Could not locate table boundaries.\n",
      "\n",
      "No data was extracted to consolidate.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the path to your raw data folder\n",
    "raw_data_path = '../data/raw/'\n",
    "press_release_files = glob.glob(os.path.join(raw_data_path, 'Press Release for auction of G-Sec-*.pdf'))\n",
    "\n",
    "print(f\"Found {len(press_release_files)} press release files to process.\")\n",
    "\n",
    "all_tables_as_df = []\n",
    "\n",
    "# Loop through each PDF file\n",
    "for file in press_release_files:\n",
    "    print(f\"\\nProcessing file: {os.path.basename(file)}...\")\n",
    "    try:\n",
    "        doc = fitz.open(file)\n",
    "        page = doc[0]\n",
    "        text = page.get_text(\"text\")\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        # --- MORE FLEXIBLE MARKERS ---\n",
    "        table_start_index = -1\n",
    "        table_end_index = -1\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            # Look for a line that is likely the header\n",
    "            if \"Security\" in line and \"Amount\" in line and \"Maturity\" in line:\n",
    "                table_start_index = i + 1\n",
    "            # Look for the line that starts the concluding paragraphs\n",
    "            if \"auction will be conducted\" in line.lower() and table_start_index != -1:\n",
    "                table_end_index = i\n",
    "                break\n",
    "        \n",
    "        if table_start_index != -1 and table_end_index != -1:\n",
    "            table_lines = lines[table_start_index:table_end_index]\n",
    "            \n",
    "            parsed_data = []\n",
    "            for line in table_lines:\n",
    "                row_data = re.split(r'\\s{2,}', line.strip())\n",
    "                if len(row_data) > 3:\n",
    "                    parsed_data.append(row_data)\n",
    "            \n",
    "            if parsed_data:\n",
    "                df = pd.DataFrame(parsed_data)\n",
    "                \n",
    "                headers = [\n",
    "                    \"name_of_the_security\", \"date_of_issue\", \"date_of_maturity\", \n",
    "                    \"coupon_rate\", \"notified_amount\", \"competitive_bids\", \"non_competitive_bids\"\n",
    "                ]\n",
    "                \n",
    "                # Ensure correct number of columns before assigning headers\n",
    "                if len(df.columns) == len(headers):\n",
    "                    df.columns = headers\n",
    "                    df['source_file'] = os.path.basename(file)\n",
    "                    all_tables_as_df.append(df)\n",
    "                    print(f\"Successfully extracted and parsed table with {len(df)} rows.\")\n",
    "                else:\n",
    "                    print(f\"--> Warning: Column count mismatch. Found {len(df.columns)}, expected {len(headers)}.\")\n",
    "            else:\n",
    "                print(\"--> Warning: No data rows were parsed from the located table.\")\n",
    "\n",
    "        else:\n",
    "            print(\"--> Warning: Could not locate table boundaries.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"--> An error occurred: {e}\")\n",
    "\n",
    "# --- CONSOLIDATE AND SAVE ---\n",
    "if all_tables_as_df:\n",
    "    consolidated_df = pd.concat(all_tables_as_df, ignore_index=True)\n",
    "    \n",
    "    output_path = '../data/processed/consolidated_gsec_auctions.csv'\n",
    "    consolidated_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nSuccessfully consolidated data from all files into:\")\n",
    "    print(output_path)\n",
    "    \n",
    "    print(\"\\n--- Preview of Consolidated Data ---\")\n",
    "    print(consolidated_df.head())\n",
    "else:\n",
    "    print(\"\\nNo data was extracted to consolidate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
